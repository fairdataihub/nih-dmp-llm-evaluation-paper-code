{
  "name": "nih-dmp-llm-evaluation-paper-code",
  "@context": "https://w3id.org/codemeta/3.0",
  "author": [
    {
      "affiliation": {
        "name": "FAIR Data Innovations Hub, California Medical Innovations Institute",
        "type": "Organization"
      },
      "email": "nzeinali@calmi2.org",
      "familyName": "Zeinali",
      "id": "_:author_1",
      "givenName": "Nahid",
      "type": "Person"
    },
    {
      "affiliation": {
        "name": "FAIR Data Innovations Hub, California Medical Innovations Institute",
        "type": "Organization"
      },
      "email": "bpatel@calmi2.org",
      "familyName": "Patel",
      "id": "_:author_2",
      "givenName": "Bhavesh",
      "type": "Person"
    }
  ],
  "codeRepository": "https://github.com/fairdataihub/nih-dmp-llm-evaluation-paper-code",
  "dateCreated": "2026-02-21",
  "description": "Large language models are increasingly used to draft NIH Data Management Plans (DMPs), but their quality and policy alignment require careful evaluation. This repository contains the code for our systematic assessment of Llama 3.3 and GPT-4.1 using both automated metrics and human expert review. See the project inventory for related resources, including the paper and dataset.",
  "issueTracker": "https://github.com/fairdataihub/nih-dmp-llm-evaluation-paper-code/issues",
  "keywords": [
    "LLM",
    "DMPs",
    "NIH",
    "evaluation",
    "FAIR Data Innovations Hub"
  ],
  "license": "https://spdx.org/licenses/MIT",
  "programmingLanguage": [
    "Python"
  ],
  "type": "SoftwareSourceCode"
}
