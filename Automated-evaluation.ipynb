{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: derivative\\automated-evaluation\\filtered_Gpt.csv | rows=312\n",
      "status\n",
      "ok    312\n",
      "Name: count, dtype: int64\n",
      "Saved: derivative\\automated-evaluation\\filtered_Llama.csv | rows=312\n",
      "status\n",
      "ok    312\n",
      "Name: count, dtype: int64\n",
      "Done: Step 5 (UPDATED)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PRIMARY_DIR = Path(\"primary\")\n",
    "HUMAN_XLSX  = PRIMARY_DIR / \"Human.xlsx\"\n",
    "GPT_DIR     = PRIMARY_DIR / \"gpt-DMPs\"\n",
    "LLAMA_DIR   = PRIMARY_DIR / \"llama-DMPs\"\n",
    "\n",
    "DERIV_DIR = Path(\"derivative/automated-evaluation\")\n",
    "DERIV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GPT_OUT_CSV   = DERIV_DIR / \"filtered_Gpt.csv\"\n",
    "LLAMA_OUT_CSV = DERIV_DIR / \"filtered_Llama.csv\"\n",
    "\n",
    "def norm_text(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def clean_title_for_match(name: str) -> str:\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r'[\\\\/*?:\"<>|]', \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_md_stem(stem: str) -> str:\n",
    "    s = (stem or \"\").strip().lower()\n",
    "    s = re.sub(r\"[-_\\s]?gpt[-_\\s]?[\\d\\.]+$\", \"\", s)\n",
    "    s = re.sub(r\"[-_\\s]?llama[-_\\s]?[\\d\\.]+$\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def find_md_by_excel_title(search_dir: Path, excel_title: str) -> Path | None:\n",
    "    excel_norm = norm_text(clean_title_for_match(excel_title))\n",
    "    md_files = list(search_dir.rglob(\"*.md\"))\n",
    "\n",
    "    for p in md_files:\n",
    "        if normalize_md_stem(p.stem) == excel_norm:\n",
    "            return p\n",
    "\n",
    "    candidates = [p for p in md_files if excel_norm and excel_norm in normalize_md_stem(p.stem)]\n",
    "    if candidates:\n",
    "        candidates = sorted(candidates, key=lambda x: (len(x.stem), str(x)))\n",
    "        return candidates[0]\n",
    "    return None\n",
    "\n",
    "def is_title(line: str) -> bool:\n",
    "    \"\"\"\n",
    "    Title detection for NIH template-style outputs:\n",
    "    - Markdown headers: #, ##, ...\n",
    "    - Numbered bold prompts: 1. **...**\n",
    "    - Bold element headers: **Element 2: ...**\n",
    "    \"\"\"\n",
    "    s = (line or \"\").strip()\n",
    "    if not s:\n",
    "        return False\n",
    "\n",
    "    if s.startswith(\"#\"):\n",
    "        return True\n",
    "\n",
    "    # 1. **Types...**\n",
    "    if re.match(r\"^\\s*\\d+[\\.\\)]?\\s*\\*\\*.+\\*\\*\\s*:?\\s*$\", s):\n",
    "        return True\n",
    "\n",
    "    # **Element 2: Related Tools...**\n",
    "    if re.match(r\"^\\s*\\*\\*\\s*element\\s*\\d+\\s*:\\s*.+\\*\\*\\s*:?\\s*$\", s, flags=re.I):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def extract_titles_and_text(md_text: str, content_col: str) -> pd.DataFrame:\n",
    "    cleaned = re.sub(r\"<think>.*?</think>\", \"\", md_text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    lines = cleaned.splitlines()\n",
    "\n",
    "    rows = []\n",
    "    current_title = None\n",
    "    buf = []\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current_title, buf, rows\n",
    "        if current_title is None:\n",
    "            return\n",
    "        text = \"\\n\".join(buf).strip()\n",
    "        if text:\n",
    "            rows.append({\"Element title\": current_title.strip(), content_col: text})\n",
    "\n",
    "    for line in lines:\n",
    "        if is_title(line):\n",
    "            flush()\n",
    "            current_title = line\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(line)\n",
    "\n",
    "    flush()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def choose_title_column(df: pd.DataFrame) -> str:\n",
    "    candidates = [\"title\", \"Title\", \"dmp_title\", \"DMP Title\", \"DMP_title\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find title column. Columns: {list(df.columns)}\")\n",
    "\n",
    "human_df = pd.read_excel(HUMAN_XLSX)\n",
    "title_col = choose_title_column(human_df)\n",
    "titles = human_df[title_col].dropna().astype(str).tolist()\n",
    "\n",
    "def process_model_folder(model_dir: Path, content_col: str, out_csv: Path) -> pd.DataFrame:\n",
    "    records = []\n",
    "\n",
    "    for title in titles:\n",
    "        md_path = find_md_by_excel_title(model_dir, title)\n",
    "\n",
    "        if md_path is None:\n",
    "            records.append({\n",
    "                \"dmp_title\": title,\n",
    "                \"md_path\": None,\n",
    "                \"Element title\": None,\n",
    "                content_col: None,\n",
    "                \"status\": \"missing_md\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        md_text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        df_sec = extract_titles_and_text(md_text, content_col=content_col)\n",
    "\n",
    "        if df_sec.empty:\n",
    "            records.append({\n",
    "                \"dmp_title\": title,\n",
    "                \"md_path\": str(md_path),\n",
    "                \"Element title\": None,\n",
    "                content_col: None,\n",
    "                \"status\": \"no_sections_found\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        for _, r in df_sec.iterrows():\n",
    "            records.append({\n",
    "                \"dmp_title\": title,\n",
    "                \"md_path\": str(md_path),\n",
    "                \"Element title\": r[\"Element title\"],\n",
    "                content_col: r[content_col],\n",
    "                \"status\": \"ok\"\n",
    "            })\n",
    "\n",
    "    out_df = pd.DataFrame(records)\n",
    "    out_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved: {out_csv} | rows={len(out_df)}\")\n",
    "    print(out_df[\"status\"].value_counts(dropna=False))\n",
    "    return out_df\n",
    "\n",
    "process_model_folder(GPT_DIR,   \"Generated_Gpt_content\",   GPT_OUT_CSV)\n",
    "process_model_folder(LLAMA_DIR, \"Generated_Llama_content\", LLAMA_OUT_CSV)\n",
    "\n",
    "print(\"Done: Step 5 (UPDATED)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: derivative\\automated-evaluation\\merged_output_Gpt.csv | rows=312\n",
      "Saved: derivative\\automated-evaluation\\merged_output_Llama.csv | rows=312\n",
      "Done: Step 6 (UPDATED)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PRIMARY_DIR = Path(\"primary\")\n",
    "HUMAN_XLSX  = PRIMARY_DIR / \"Human.xlsx\"\n",
    "\n",
    "DERIV_DIR = Path(\"derivative/automated-evaluation\")\n",
    "GPT_FILTERED   = DERIV_DIR / \"filtered_Gpt.csv\"\n",
    "LLAMA_FILTERED = DERIV_DIR / \"filtered_Llama.csv\"\n",
    "\n",
    "GPT_MERGED   = DERIV_DIR / \"merged_output_Gpt.csv\"\n",
    "LLAMA_MERGED = DERIV_DIR / \"merged_output_Llama.csv\"\n",
    "\n",
    "def norm_text(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def choose_title_column(df: pd.DataFrame) -> str:\n",
    "    candidates = [\"title\", \"Title\", \"dmp_title\", \"DMP Title\", \"DMP_title\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find title column. Columns: {list(df.columns)}\")\n",
    "\n",
    "def get_element_columns(df: pd.DataFrame) -> list:\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        cc = str(c).strip().lower()\n",
    "        if re.match(r\"^element_\\d+[a-z]?$\", cc):\n",
    "            cols.append(cc)\n",
    "    if not cols:\n",
    "        raise ValueError(\"No element_* columns found in Human.xlsx.\")\n",
    "\n",
    "    def sort_key(c):\n",
    "        m = re.match(r\"^element_(\\d+)([a-z]?)$\", c)\n",
    "        return (int(m.group(1)), m.group(2) or \"\")\n",
    "    return sorted(cols, key=sort_key)\n",
    "\n",
    "def map_section_title_to_element(section_title) -> str | None:\n",
    "    if section_title is None:\n",
    "        return None\n",
    "    try:\n",
    "        if pd.isna(section_title):\n",
    "            return None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    t = str(section_title).strip()\n",
    "    t_plain = re.sub(r\"^#+\\s*\", \"\", t).strip()\n",
    "    t_low = t_plain.lower()\n",
    "\n",
    "    # Element headers\n",
    "    if re.search(r\"\\belement\\s*2\\b\", t_low): return \"element_2\"\n",
    "    if re.search(r\"\\belement\\s*3\\b\", t_low): return \"element_3\"\n",
    "    if re.search(r\"\\belement\\s*6\\b\", t_low): return \"element_6\"\n",
    "\n",
    "    # Element 1 sub-questions (1a/1b/1c)\n",
    "    if \"types and amount of scientific data\" in t_low: return \"element_1a\"\n",
    "    if \"scientific data that will be preserved and shared\" in t_low: return \"element_1b\"\n",
    "    if \"metadata, other relevant data, and associated documentation\" in t_low: return \"element_1c\"\n",
    "\n",
    "    # Element 4 sub-questions (4a/4b/4c)\n",
    "    if \"repository where scientific data and metadata will be archived\" in t_low: return \"element_4a\"\n",
    "    if \"how scientific data will be findable and identifiable\" in t_low: return \"element_4b\"\n",
    "    if \"when and how long the scientific data will be made available\" in t_low: return \"element_4c\"\n",
    "\n",
    "    # Element 5 sub-questions (5a/5b/5c)\n",
    "    if \"factors affecting subsequent access, distribution, or reuse\" in t_low: return \"element_5a\"\n",
    "    if \"whether access to scientific data will be controlled\" in t_low: return \"element_5b\"\n",
    "    if \"protections for privacy, rights, and confidentiality\" in t_low: return \"element_5c\"\n",
    "\n",
    "    return None\n",
    "\n",
    "# NIH reference\n",
    "ref = pd.read_excel(HUMAN_XLSX)\n",
    "title_col = choose_title_column(ref)\n",
    "ref = ref.rename(columns={title_col: \"title\"})\n",
    "ref.columns = [str(c).strip().lower() for c in ref.columns]\n",
    "\n",
    "ref[\"title_norm\"] = ref[\"title\"].apply(norm_text)\n",
    "element_cols = get_element_columns(ref)\n",
    "\n",
    "ref_long = ref[[\"title\", \"title_norm\"] + element_cols].fillna(\"\").melt(\n",
    "    id_vars=[\"title\", \"title_norm\"],\n",
    "    value_vars=element_cols,\n",
    "    var_name=\"Element number\",\n",
    "    value_name=\"NIH Value\",\n",
    ")\n",
    "ref_long[\"Element number\"] = ref_long[\"Element number\"].str.lower().str.strip()\n",
    "\n",
    "def load_model_filtered(path: Path, content_col: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"title_norm\"] = df[\"dmp_title\"].apply(norm_text)\n",
    "    df[\"Element title\"] = df[\"Element title\"].fillna(\"\").astype(str)\n",
    "\n",
    "    df[\"Element number\"] = df[\"Element title\"].apply(map_section_title_to_element)\n",
    "    df = df[df[\"Element number\"].notna()].copy()\n",
    "    df[\"Element number\"] = df[\"Element number\"].str.lower().str.strip()\n",
    "\n",
    "    df = df.rename(columns={content_col: \"Generated Content\"})\n",
    "    return df[[\"title_norm\", \"Element number\", \"Element title\", \"Generated Content\"]]\n",
    "\n",
    "gpt_sec = load_model_filtered(GPT_FILTERED, \"Generated_Gpt_content\")\n",
    "llm_sec = load_model_filtered(LLAMA_FILTERED, \"Generated_Llama_content\")\n",
    "\n",
    "def merge_and_save(sec_df: pd.DataFrame, out_path: Path):\n",
    "    merged = ref_long.merge(sec_df, on=[\"title_norm\", \"Element number\"], how=\"left\")\n",
    "    merged = merged[[\"title\", \"Element number\", \"NIH Value\", \"Element title\", \"Generated Content\"]]\n",
    "    merged.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved: {out_path} | rows={len(merged)}\")\n",
    "\n",
    "merge_and_save(gpt_sec, GPT_MERGED)\n",
    "merge_and_save(llm_sec, LLAMA_MERGED)\n",
    "\n",
    "print(\"Done: Step 6 (UPDATED)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: derivative\\automated-evaluation\\merged_output_Gpt_cleaned.csv | rows=156\n",
      "Element counts: {'element_1': 26, 'element_2': 26, 'element_3': 26, 'element_4': 26, 'element_5': 26, 'element_6': 26}\n",
      " Saved: derivative\\automated-evaluation\\merged_output_Llama_cleaned.csv | rows=156\n",
      "Element counts: {'element_1': 26, 'element_2': 26, 'element_3': 26, 'element_4': 26, 'element_5': 26, 'element_6': 26}\n",
      "Done: Step 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DERIV_DIR = Path(\"derivative/automated-evaluation\")\n",
    "DERIV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUTS = {\n",
    "    \"Gpt\": DERIV_DIR / \"merged_output_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"merged_output_Llama.csv\",\n",
    "}\n",
    "OUTPUTS = {\n",
    "    \"Gpt\": DERIV_DIR / \"merged_output_Gpt_cleaned.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"merged_output_Llama_cleaned.csv\",\n",
    "}\n",
    "\n",
    "# Collapse these sub-elements into one per title\n",
    "group_map = {\n",
    "    \"element_1\": [\"element_1a\", \"element_1b\", \"element_1c\"],\n",
    "    \"element_4\": [\"element_4a\", \"element_4b\", \"element_4c\"],\n",
    "    \"element_5\": [\"element_5a\", \"element_5b\", \"element_5c\"],\n",
    "}\n",
    "\n",
    "def clean_text(x) -> str:\n",
    "    \"\"\"Trim + normalize blank lines; safe for NaN.\"\"\"\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(x).strip()\n",
    "    s = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", s)  # collapse multi-blank lines\n",
    "    return s\n",
    "\n",
    "def sort_element_key(x: str):\n",
    "    \"\"\"element_1, element_2, ... element_6 ordering.\"\"\"\n",
    "    s = str(x).strip().lower()\n",
    "    m = re.match(r\"^element_(\\d+)([a-z]?)$\", s)\n",
    "    if not m:\n",
    "        return (999, \"z\", s)\n",
    "    return (int(m.group(1)), m.group(2) or \"\", s)\n",
    "\n",
    "def combine_group_for_title(df_title: pd.DataFrame, new_element: str, group: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Combine NIH Value and Generated Content for the given group, preserving group order.\n",
    "    \"\"\"\n",
    "    g = df_title[df_title[\"Element number\"].isin(group)].copy()\n",
    "    g[\"Element number\"] = pd.Categorical(g[\"Element number\"], categories=group, ordered=True)\n",
    "    g = g.sort_values(\"Element number\")\n",
    "\n",
    "    nih = \"\\n\\n\".join([clean_text(v) for v in g[\"NIH Value\"].tolist() if clean_text(v)])\n",
    "    gen = \"\\n\\n\".join([clean_text(v) for v in g[\"Generated Content\"].tolist() if clean_text(v)])\n",
    "\n",
    "    return {\n",
    "        \"Element number\": new_element,\n",
    "        \"NIH Value\": nih,\n",
    "        \"Generated Content\": gen,\n",
    "    }\n",
    "\n",
    "for model_name, in_path in INPUTS.items():\n",
    "    if not in_path.exists():\n",
    "        print(f\" Missing input: {in_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    required = {\"title\", \"Element number\", \"NIH Value\", \"Generated Content\"}\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{in_path} missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    # normalize\n",
    "    df[\"Element number\"] = df[\"Element number\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "    group_flat = [e for grp in group_map.values() for e in grp]\n",
    "    out_blocks = []\n",
    "\n",
    "    # IMPORTANT: combine within each title\n",
    "    for title, df_title in df.groupby(\"title\", dropna=False):\n",
    "        df_title = df_title.copy()\n",
    "\n",
    "        keep_df = df_title[~df_title[\"Element number\"].isin(group_flat)].copy()\n",
    "        keep_df = keep_df[[\"Element number\", \"NIH Value\", \"Generated Content\"]]\n",
    "\n",
    "        merged_rows = []\n",
    "        for new_element, grp in group_map.items():\n",
    "            merged_rows.append(combine_group_for_title(df_title, new_element, grp))\n",
    "\n",
    "        final_title_df = pd.concat(\n",
    "            [keep_df, pd.DataFrame(merged_rows)],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        # clean text\n",
    "        for col in [\"NIH Value\", \"Generated Content\"]:\n",
    "            final_title_df[col] = final_title_df[col].apply(clean_text)\n",
    "\n",
    "        # sort + attach title\n",
    "        final_title_df = final_title_df.sort_values(\n",
    "            by=\"Element number\",\n",
    "            key=lambda s: s.map(sort_element_key)\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        final_title_df.insert(0, \"title\", title)\n",
    "        out_blocks.append(final_title_df)\n",
    "\n",
    "    final_df = pd.concat(out_blocks, ignore_index=True)\n",
    "\n",
    "    out_path = OUTPUTS[model_name]\n",
    "    final_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # quick sanity check\n",
    "    print(f\" Saved: {out_path} | rows={len(final_df)}\")\n",
    "    print(\"Element counts:\", final_df[\"Element number\"].value_counts().to_dict())\n",
    "\n",
    "print(\"Done: Step 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1596.54it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved Step 8 outputs for Gpt:\n",
      "   - derivative/automated-evaluation/dmp_similarity_summary_Gpt.csv\n",
      "   - derivative/automated-evaluation/element_similarity_raw_Gpt.csv\n",
      "   - derivative/automated-evaluation/element_similarity_summary_Gpt.csv\n",
      " Saved Step 8 outputs for Llama:\n",
      "   - derivative/automated-evaluation/dmp_similarity_summary_Llama.csv\n",
      "   - derivative/automated-evaluation/element_similarity_raw_Llama.csv\n",
      "   - derivative/automated-evaluation/element_similarity_summary_Llama.csv\n",
      "Done: Step 8\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "DERIV_DIR = Path(\"derivative/automated-evaluation\")\n",
    "\n",
    "INPUTS = {\n",
    "    \"Gpt\":   DERIV_DIR / \"merged_output_Gpt_cleaned.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"merged_output_Llama_cleaned.csv\",\n",
    "}\n",
    "\n",
    "OUT_FOLDER = {\n",
    "    \"Gpt\":   DERIV_DIR / \"dmp_similarity_summary_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"dmp_similarity_summary_Llama.csv\",\n",
    "}\n",
    "OUT_RAW = {\n",
    "    \"Gpt\":   DERIV_DIR / \"element_similarity_raw_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"element_similarity_raw_Llama.csv\",\n",
    "}\n",
    "OUT_ELEMENT = {\n",
    "    \"Gpt\":   DERIV_DIR / \"element_similarity_summary_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"element_similarity_summary_Llama.csv\",\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Models\n",
    "# -----------------------------\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def safe_text(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(x)\n",
    "\n",
    "def rougeL_recall(ref: str, gen: str) -> float:\n",
    "    ref = ref or \"\"\n",
    "    gen = gen or \"\"\n",
    "    if not ref.strip() and not gen.strip():\n",
    "        return 1.0\n",
    "    if not ref.strip() or not gen.strip():\n",
    "        return 0.0\n",
    "    return float(rouge.score(ref, gen)[\"rougeL\"].recall)\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "for model_name, in_path in INPUTS.items():\n",
    "    if not in_path.exists():\n",
    "        print(f\" Missing input: {in_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    required = {\"title\", \"Element number\", \"NIH Value\", \"Generated Content\"}\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{in_path} missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    # normalize\n",
    "    df[\"title\"] = df[\"title\"].apply(safe_text)\n",
    "    df[\"Element number\"] = df[\"Element number\"].apply(safe_text).str.strip().str.lower()\n",
    "    df[\"NIH Value\"] = df[\"NIH Value\"].apply(safe_text)\n",
    "    df[\"Generated Content\"] = df[\"Generated Content\"].apply(safe_text)\n",
    "\n",
    "    # ---- SBERT (batch encode) ----\n",
    "    nih_texts = df[\"NIH Value\"].tolist()\n",
    "    gen_texts = df[\"Generated Content\"].tolist()\n",
    "\n",
    "    # Encode in batches; normalize embeddings for stable cosine similarity\n",
    "    emb_nih = sbert.encode(nih_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb_gen = sbert.encode(gen_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "    # Cosine similarity per row (dot product works because normalized)\n",
    "    sbert_sims = (emb_nih * emb_gen).sum(dim=1).cpu().numpy().astype(float)\n",
    "\n",
    "    # ---- ROUGE-L recall (row-wise) ----\n",
    "    rouge_recalls = [\n",
    "        rougeL_recall(r, g) for r, g in zip(nih_texts, gen_texts)\n",
    "    ]\n",
    "\n",
    "    raw = pd.DataFrame({\n",
    "        \"Model\": model_name,\n",
    "        \"DMP Title\": df[\"title\"],\n",
    "        \"Element number\": df[\"Element number\"],\n",
    "        \"SBERT_Similarity\": sbert_sims,\n",
    "        \"ROUGE_L_Recall\": rouge_recalls,\n",
    "    })\n",
    "\n",
    "    # Folder (DMP)-level summary\n",
    "    folder_summary = (\n",
    "        raw.groupby([\"Model\", \"DMP Title\"], as_index=False)[[\"SBERT_Similarity\", \"ROUGE_L_Recall\"]]\n",
    "           .mean()\n",
    "           .rename(columns={\"DMP Title\": \"Folder\"})\n",
    "    )\n",
    "\n",
    "    # Element-level summary\n",
    "    element_summary = (\n",
    "        raw.groupby([\"Model\", \"Element number\"], as_index=False)[[\"SBERT_Similarity\", \"ROUGE_L_Recall\"]]\n",
    "           .mean()\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    raw.to_csv(OUT_RAW[model_name], index=False, encoding=\"utf-8\")\n",
    "    folder_summary.to_csv(OUT_FOLDER[model_name], index=False, encoding=\"utf-8\")\n",
    "    element_summary.to_csv(OUT_ELEMENT[model_name], index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\" Saved Step 8 outputs for {model_name}:\")\n",
    "    print(f\"   - {OUT_FOLDER[model_name].as_posix()}\")\n",
    "    print(f\"   - {OUT_RAW[model_name].as_posix()}\")\n",
    "    print(f\"   - {OUT_ELEMENT[model_name].as_posix()}\")\n",
    "\n",
    "print(\"Done: Step 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: derivative/automated-evaluation/sub_element_similarity_summary_Gpt.csv | rows=12\n",
      " Saved: derivative/automated-evaluation/sub_element_similarity_summary_Llama.csv | rows=12\n",
      "Done: Step 8c (sub-element summaries)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ✅ STEP 8c — Sub-element similarity summary (1a/1b/1c, 4a/4b/4c, 5a/5b/5c)\n",
    "#     (does NOT change Step 8; just adds 2 more files)\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "DERIV_DIR = Path(\"derivative/automated-evaluation\")\n",
    "\n",
    "# Use NON-cleaned merged files so sub-elements are preserved\n",
    "INPUTS_SUB = {\n",
    "    \"Gpt\":   DERIV_DIR / \"merged_output_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"merged_output_Llama.csv\",\n",
    "}\n",
    "\n",
    "OUT_SUB_ELEMENT = {\n",
    "    \"Gpt\":   DERIV_DIR / \"sub_element_similarity_summary_Gpt.csv\",\n",
    "    \"Llama\": DERIV_DIR / \"sub_element_similarity_summary_Llama.csv\",\n",
    "}\n",
    "\n",
    "# Reuse models if they already exist\n",
    "try:\n",
    "    sbert\n",
    "except NameError:\n",
    "    sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "try:\n",
    "    rouge\n",
    "except NameError:\n",
    "    rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "def safe_text(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(x)\n",
    "\n",
    "def rougeL_recall(ref: str, gen: str) -> float:\n",
    "    ref = ref or \"\"\n",
    "    gen = gen or \"\"\n",
    "    if not ref.strip() and not gen.strip():\n",
    "        return 1.0\n",
    "    if not ref.strip() or not gen.strip():\n",
    "        return 0.0\n",
    "    return float(rouge.score(ref, gen)[\"rougeL\"].recall)\n",
    "\n",
    "def sort_element_key(x: str):\n",
    "    \"\"\"\n",
    "    Sort like: element_1a, element_1b, element_1c, element_2, element_3, element_4a...\n",
    "    \"\"\"\n",
    "    s = str(x).strip().lower()\n",
    "    import re\n",
    "    m = re.match(r\"^element_(\\d+)([a-z]?)$\", s)\n",
    "    if not m:\n",
    "        return (999, \"z\", s)\n",
    "    return (int(m.group(1)), m.group(2) or \"\", s)\n",
    "\n",
    "for model_name, in_path in INPUTS_SUB.items():\n",
    "    if not in_path.exists():\n",
    "        print(f\" Missing input for sub-element summary: {in_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    required = {\"title\", \"Element number\", \"NIH Value\", \"Generated Content\"}\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{in_path} missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    # normalize\n",
    "    df[\"title\"] = df[\"title\"].apply(safe_text)\n",
    "    df[\"Element number\"] = df[\"Element number\"].apply(safe_text).str.strip().str.lower()\n",
    "    df[\"NIH Value\"] = df[\"NIH Value\"].apply(safe_text)\n",
    "    df[\"Generated Content\"] = df[\"Generated Content\"].apply(safe_text)\n",
    "\n",
    "    # SBERT (batch encode)\n",
    "    nih_texts = df[\"NIH Value\"].tolist()\n",
    "    gen_texts = df[\"Generated Content\"].tolist()\n",
    "\n",
    "    emb_nih = sbert.encode(nih_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb_gen = sbert.encode(gen_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "    sbert_sims = (emb_nih * emb_gen).sum(dim=1).cpu().numpy().astype(float)\n",
    "    rouge_recalls = [rougeL_recall(r, g) for r, g in zip(nih_texts, gen_texts)]\n",
    "\n",
    "    raw = pd.DataFrame({\n",
    "        \"Model\": model_name,\n",
    "        \"Element number\": df[\"Element number\"],   # <-- sub-elements preserved here\n",
    "        \"SBERT_Similarity\": sbert_sims,\n",
    "        \"ROUGE_L_Recall\": rouge_recalls,\n",
    "    })\n",
    "\n",
    "    # ✅ Sub-element summary (mean per element_1a, element_1b, ..., element_6)\n",
    "    sub_element_summary = (\n",
    "        raw.groupby([\"Model\", \"Element number\"], as_index=False)[[\"SBERT_Similarity\", \"ROUGE_L_Recall\"]]\n",
    "           .mean()\n",
    "    )\n",
    "\n",
    "    # nice ordering\n",
    "    sub_element_summary = sub_element_summary.sort_values(\n",
    "        by=\"Element number\",\n",
    "        key=lambda s: s.map(sort_element_key)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    sub_element_summary.to_csv(OUT_SUB_ELEMENT[model_name], index=False, encoding=\"utf-8\")\n",
    "    print(f\" Saved: {OUT_SUB_ELEMENT[model_name].as_posix()} | rows={len(sub_element_summary)}\")\n",
    "\n",
    "print(\"Done: Step 8c (sub-element summaries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
